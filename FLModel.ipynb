{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "472425b580dddcaf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:11.180375600Z",
     "start_time": "2023-10-30T19:53:11.132389100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "import sys\n",
    "import time\n",
    "import platform, cpuinfo, GPUtil, psutil\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows 10\n",
      "CPU: 13th Gen Intel(R) Core(TM) i9-13900H\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory: 31.73 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"OS: {platform.uname().system} {platform.uname().release}\")\n",
    "print(f\"CPU: {cpuinfo.get_cpu_info()['brand_raw']}\")\n",
    "print(f\"GPU: {GPUtil.getGPUs()[0].name}\")\n",
    "print(f\"Memory: {psutil.virtual_memory().total / (1024 ** 3):.2f} GB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.596797100Z",
     "start_time": "2023-10-30T19:53:11.142546Z"
    }
   },
   "id": "4ba5cc17f1cd99fd"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "Version info: sys.version_info(major=3, minor=11, micro=4, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Python version:\", sys.version)\n",
    "print(\"Version info:\", sys.version_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.597861600Z",
     "start_time": "2023-10-30T19:53:12.587658Z"
    }
   },
   "id": "a03c08d2241fc3fe"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.0.1+cpu and Flower 1.5.0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.608780800Z",
     "start_time": "2023-10-30T19:53:12.593582500Z"
    }
   },
   "id": "f80cb111f6bc6cc6"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6ed94bf98631bf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.618023Z",
     "start_time": "2023-10-30T19:53:12.608780800Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 3\n",
    "EPOCHS = 10\n",
    "ROUNDS = 5\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IN_FEATURES = 3\n",
    "HIDDEN_LAYERS = 80\n",
    "OUT_FEATURES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    df = pd.read_csv('./datasets/label_data.csv')\n",
    "    \n",
    "    feature = df.iloc[:, :-1]\n",
    "    target = df.loc[:, 'label']\n",
    "    feature = torch.Tensor(feature.to_numpy())\n",
    "    target = torch.tensor(target.to_numpy())\n",
    "    tensor_data = TensorDataset(feature, target)\n",
    "    \n",
    "    split_ratio = 0.8\n",
    "    train_split = int(len(feature) * split_ratio)\n",
    "    test_split = len(feature) - train_split\n",
    "    while train_split % NUM_CLIENTS != 0:\n",
    "        train_split -= 1\n",
    "        test_split += 1\n",
    "    train_set, test_set = random_split(tensor_data, [train_split, test_split])  \n",
    "\n",
    "    # split_index = int(len(df) * split_ratio)\n",
    "    # train_set = tensor_data.iloc[:split_index, :]\n",
    "    # test_set = tensor_data.iloc[split_index:, :]\n",
    "    \n",
    "    part_size = len(train_set) // NUM_CLIENTS\n",
    "    length = [part_size] * NUM_CLIENTS  # lengths for each client\n",
    "    \n",
    "    # Split the test set evenly into thirds, removing the remainders\n",
    "    # random_choose = np.random.choice(train_set.index, (len(train_set) % NUM_CLIENTS), replace=False)\n",
    "    # train_set = train_set.drop(random_choose)\n",
    "    \n",
    "    datasets = random_split(train_set, length, generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    \n",
    "    for data in datasets:\n",
    "        val_length = len(data) // 10  # 10% for validation \n",
    "        \n",
    "        train_length = len(data) - val_length\n",
    "        length = [train_length, val_length]\n",
    "        train_data, val_data = random_split(data, length, generator=torch.Generator().manual_seed(42))\n",
    "        \n",
    "        train_loader.append(DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        val_loader.append(DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True))\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return train_loader, val_loader, test_loader\n",
    "    \n",
    "train_loader, val_loader, test_loader = load_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.868637800Z",
     "start_time": "2023-10-30T19:53:12.615516400Z"
    }
   },
   "id": "7953758d82a33194"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(IN_FEATURES, HIDDEN_LAYERS), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYERS, HIDDEN_LAYERS), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYERS, OUT_FEATURES), \n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.887981600Z",
     "start_time": "2023-10-30T19:53:12.868637800Z"
    }
   },
   "id": "7de944941f3254ed"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1): \n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        \n",
    "        for feature, target in train_loader:\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(feature)\n",
    "            train_loss = criterion(output, target)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += train_loss\n",
    "            total += target.size(0)\n",
    "            correct += (torch.max(output.data, 1)[1] == target).sum().item()\n",
    "            \n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_accuracy = correct / total\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{EPOCHS}: train loss is {epoch_loss:.4f}, accuracy is {epoch_accuracy:.4f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.888486800Z",
     "start_time": "2023-10-30T19:53:12.872739100Z"
    }
   },
   "id": "3b7767fe074ec24"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    actual_labels = []\n",
    "    predicted_labels = []\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for feature, target in test_loader:\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(feature)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            loss += criterion(output, target).item()\n",
    "            # total += target.size(0)\n",
    "            # correct += (predicted == target).sum().item()\n",
    "            \n",
    "            actual_labels.extend(target.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            \n",
    "        loss /= len(test_loader.dataset)\n",
    "        # accuracy = correct / total\n",
    "        # return loss, accuracy\n",
    "        \n",
    "    accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    print(\"Testing Result:\"\n",
    "          \"\\n----------------------------------------------------------------------------------------\")\n",
    "    print(f\"Loss: {loss:.4f}   Accuracy: {accuracy:.4f}   Precision: {precision:.4f}   Recall: {recall:.4f}   F1-Score: {f1:.4f}\"\n",
    "          f\"\\n----------------------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:53:12.897999400Z",
     "start_time": "2023-10-30T19:53:12.881594400Z"
    }
   },
   "id": "b55c029f8b011706"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: train loss is 0.0144, accuracy is 0.8589.\n",
      "Epoch 2/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 3/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 4/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 5/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 6/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 7/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 8/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 9/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "Epoch 10/10: train loss is 0.0141, accuracy is 0.8608.\n",
      "\n",
      "Training time: 59.8563 secs.\n",
      "Testing Result:\n",
      "----------------------------------------------------------------------------------------\n",
      "Loss: 0.0141   Accuracy: 0.8629   Precision: 0.7446   Recall: 0.8629   F1-Score: 0.7994\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# PyTorch model testing\n",
    "train_loader = train_loader[1]\n",
    "val_loader = val_loader[1]\n",
    "model = Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES).to(DEVICE)\n",
    "\n",
    "train_start = time.time()\n",
    "train(model, train_loader, EPOCHS)\n",
    "train_end = time.time()\n",
    "print(f\"\\nTraining time: {train_end - train_start:.4f} secs.\")\n",
    "\n",
    "test(model, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.185482400Z",
     "start_time": "2023-10-30T19:53:12.888486800Z"
    }
   },
   "id": "8bacc3940f61904b"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def get_parameters(model) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "def set_parameters(model, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.185482400Z",
     "start_time": "2023-10-30T19:54:13.172320500Z"
    }
   },
   "id": "53bb07e9fc48198c"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, train_loader, val_loader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"Client {self.cid} received the parameters.\")\n",
    "        return get_parameters(self.model)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"Client {self.cid} fit, config: {config}.\")\n",
    "        set_parameters(self.model, parameters)\n",
    "        train(self.model, self.train_loader, epochs=EPOCHS)\n",
    "        return get_parameters(self.model), len(self.train_loader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"Client {self.cid} evaluate, config: {config}.\")\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = test(self.model, self.val_loader)\n",
    "        return float(loss), len(self.val_loader), {'accuracy: ': float(accuracy)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.185482400Z",
     "start_time": "2023-10-30T19:54:13.176246200Z"
    }
   },
   "id": "4a938348b17084cd"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    print(f\"Client: {cid} -------------------------------------------------------------------------\")\n",
    "    model = Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES).to(DEVICE)\n",
    "    \n",
    "    train_loader, val_loader, test_loader = load_datasets()\n",
    "    train_loader = train_loader[int(cid)]\n",
    "    val_loader = val_loader[int(cid)]\n",
    "    \n",
    "    return FlowerClient(cid, model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.208479900Z",
     "start_time": "2023-10-30T19:54:13.188113700Z"
    }
   },
   "id": "21917de3493b815d"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m['accuracy'] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {'accuracy': sum(accuracies) / sum(examples)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.209067Z",
     "start_time": "2023-10-30T19:54:13.193621500Z"
    }
   },
   "id": "51dffba09b1309e9"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# params = get_parameters(Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES))\n",
    "# \n",
    "# strategy = fl.server.strategy.FedAvg(\n",
    "#     fraction_fit=1.0,\n",
    "#     fraction_evaluate=1.0,\n",
    "#     min_fit_clients=NUM_CLIENTS,\n",
    "#     min_evaluate_clients=NUM_CLIENTS,\n",
    "#     min_available_clients=NUM_CLIENTS,\n",
    "#     initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    "# )\n",
    "# \n",
    "# fl.simulation.start_simulation(\n",
    "#     client_fn=client_fn,\n",
    "#     num_clients=NUM_CLIENTS,\n",
    "#     config=fl.server.ServerConfig(num_rounds=ROUNDS),\n",
    "#     strategy=strategy,\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.212380600Z",
     "start_time": "2023-10-30T19:54:13.203912600Z"
    }
   },
   "id": "801acac2af91f221"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Citation:   \n",
    "https://flower.dev/docs/framework/tutorial-series-get-started-with-flower-pytorch.html\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "626c29ee0b4c60f5"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T19:54:13.212380600Z",
     "start_time": "2023-10-30T19:54:13.212380600Z"
    }
   },
   "id": "ca08814286feab15"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
