{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472425b580dddcaf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.066483900Z",
     "start_time": "2023-11-07T19:59:24.826399500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]\n",
      "Version info: sys.version_info(major=3, minor=11, micro=6, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Python version:\", sys.version)\n",
    "print(\"Version info:\", sys.version_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.074432100Z",
     "start_time": "2023-11-07T19:59:27.066483900Z"
    }
   },
   "id": "a03c08d2241fc3fe"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.1.0+cpu and Flower 1.5.0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.082916500Z",
     "start_time": "2023-11-07T19:59:27.074432100Z"
    }
   },
   "id": "f80cb111f6bc6cc6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ed94bf98631bf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.135519300Z",
     "start_time": "2023-11-07T19:59:27.079912400Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 3\n",
    "EPOCHS = 10\n",
    "ROUNDS = 5\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IN_FEATURES = 3\n",
    "HIDDEN_LAYERS = 80\n",
    "OUT_FEATURES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    df = pd.read_csv('./datasets/label_data.csv')\n",
    "    \n",
    "    feature = df.iloc[:, :-1]\n",
    "    target = df.loc[:, 'label']\n",
    "    feature = torch.Tensor(feature.to_numpy())\n",
    "    target = torch.tensor(target.to_numpy())\n",
    "    tensor_data = TensorDataset(feature, target)\n",
    "    \n",
    "    split_ratio = 0.8\n",
    "    train_split = int(len(feature) * split_ratio)\n",
    "    test_split = len(feature) - train_split\n",
    "    while train_split % NUM_CLIENTS != 0:\n",
    "        train_split -= 1\n",
    "        test_split += 1\n",
    "    train_set, test_set = random_split(tensor_data, [train_split, test_split])  \n",
    "\n",
    "    # split_index = int(len(df) * split_ratio)\n",
    "    # train_set = tensor_data.iloc[:split_index, :]\n",
    "    # test_set = tensor_data.iloc[split_index:, :]\n",
    "    \n",
    "    part_size = len(train_set) // NUM_CLIENTS\n",
    "    length = [part_size] * NUM_CLIENTS  # lengths for each client\n",
    "    \n",
    "    # Split the test set evenly into thirds, removing the remainders\n",
    "    # random_choose = np.random.choice(train_set.index, (len(train_set) % NUM_CLIENTS), replace=False)\n",
    "    # train_set = train_set.drop(random_choose)\n",
    "    \n",
    "    datasets = random_split(train_set, length, generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    \n",
    "    for data in datasets:\n",
    "        val_length = len(data) // 10  # 10% for validation \n",
    "        \n",
    "        train_length = len(data) - val_length\n",
    "        length = [train_length, val_length]\n",
    "        train_data, val_data = random_split(data, length, generator=torch.Generator().manual_seed(42))\n",
    "        \n",
    "        train_loader.append(DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        val_loader.append(DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True))\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return train_loader, val_loader, test_loader\n",
    "    \n",
    "train_loader, val_loader, test_loader = load_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.313357100Z",
     "start_time": "2023-11-07T19:59:27.091206900Z"
    }
   },
   "id": "7953758d82a33194"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(IN_FEATURES, HIDDEN_LAYERS), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYERS, HIDDEN_LAYERS), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYERS, OUT_FEATURES), \n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.321090Z",
     "start_time": "2023-11-07T19:59:27.317092300Z"
    }
   },
   "id": "7de944941f3254ed"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1): \n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        \n",
    "        for feature, target in train_loader:\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(feature)\n",
    "            train_loss = criterion(output, target)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += train_loss\n",
    "            total += target.size(0)\n",
    "            correct += (torch.max(output.data, 1)[1] == target).sum().item()\n",
    "            \n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_accuracy = correct / total\n",
    "        \n",
    "        print(f\"Epoch {epoch}/{EPOCHS}: train loss is {epoch_loss:.4f}, accuracy is {epoch_accuracy:.4f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.353845700Z",
     "start_time": "2023-11-07T19:59:27.321090Z"
    }
   },
   "id": "3b7767fe074ec24"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    actual_labels = []\n",
    "    predicted_labels = []\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for feature, target in test_loader:\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(feature)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            \n",
    "            loss += criterion(output, target).item()\n",
    "            # total += target.size(0)\n",
    "            # correct += (predicted == target).sum().item()\n",
    "            \n",
    "            actual_labels.extend(target.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            \n",
    "        loss /= len(test_loader.dataset)\n",
    "        # accuracy = correct / total\n",
    "        # return loss, accuracy\n",
    "        \n",
    "    accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
    "    \n",
    "    print(\"Testing Result:\"\n",
    "          \"\\n----------------------------------------------------------------------------------------\")\n",
    "    print(f\"Loss: {loss:.4f}   Accuracy: {accuracy:.4f}   Precision: {precision:.4f}   Recall: {recall:.4f}   F1-Score: {f1:.4f}\"\n",
    "          f\"\\n----------------------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.353845700Z",
     "start_time": "2023-11-07T19:59:27.337628500Z"
    }
   },
   "id": "b55c029f8b011706"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# PyTorch model testing\n",
    "\n",
    "# train_loader = train_loader[1]\n",
    "# val_loader = val_loader[1]\n",
    "# model = Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES).to(DEVICE)\n",
    "# \n",
    "# train_start = time.time()\n",
    "# train(model, train_loader, EPOCHS)\n",
    "# train_end = time.time()\n",
    "# print(f\"\\nTraining time: {train_end - train_start:.4f} secs.\")\n",
    "# \n",
    "# test(model, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.357358200Z",
     "start_time": "2023-11-07T19:59:27.345675900Z"
    }
   },
   "id": "8bacc3940f61904b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_parameters(model) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "def set_parameters(model, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(model.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.365387100Z",
     "start_time": "2023-11-07T19:59:27.357358200Z"
    }
   },
   "id": "53bb07e9fc48198c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, model, train_loader, val_loader):\n",
    "        self.cid = cid\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"Client {self.cid} received the parameters.\")\n",
    "        return get_parameters(self.model)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"Client {self.cid} fit, config: {config}.\")\n",
    "        set_parameters(self.model, parameters)\n",
    "        train(self.model, self.train_loader, epochs=EPOCHS)\n",
    "        return get_parameters(self.model), len(self.train_loader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"Client {self.cid} evaluate, config: {config}.\")\n",
    "        set_parameters(self.model, parameters)\n",
    "        loss, accuracy = test(self.model, self.val_loader)\n",
    "        return float(loss), len(self.val_loader), {'accuracy: ': float(accuracy)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.371211900Z",
     "start_time": "2023-11-07T19:59:27.365387100Z"
    }
   },
   "id": "4a938348b17084cd"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    print(f\"Client: {cid} -------------------------------------------------------------------------\")\n",
    "    model = Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES).to(DEVICE)\n",
    "    \n",
    "    train_loader, val_loader, test_loader = load_datasets()\n",
    "    train_loader = train_loader[int(cid)]\n",
    "    val_loader = val_loader[int(cid)]\n",
    "    \n",
    "    return FlowerClient(cid, model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.390549200Z",
     "start_time": "2023-11-07T19:59:27.373717200Z"
    }
   },
   "id": "21917de3493b815d"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m['accuracy'] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {'accuracy': sum(accuracies) / sum(examples)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:27.390549200Z",
     "start_time": "2023-11-07T19:59:27.381897900Z"
    }
   },
   "id": "51dffba09b1309e9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-11-07 15:59:27,394 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 系统找不到指定的文件。",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 12\u001B[0m\n\u001B[0;32m      1\u001B[0m params \u001B[38;5;241m=\u001B[39m get_parameters(Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES))\n\u001B[0;32m      3\u001B[0m strategy \u001B[38;5;241m=\u001B[39m fl\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mFedAvg(\n\u001B[0;32m      4\u001B[0m     fraction_fit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m,\n\u001B[0;32m      5\u001B[0m     fraction_evaluate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      9\u001B[0m     initial_parameters\u001B[38;5;241m=\u001B[39mfl\u001B[38;5;241m.\u001B[39mcommon\u001B[38;5;241m.\u001B[39mndarrays_to_parameters(params),\n\u001B[0;32m     10\u001B[0m )\n\u001B[1;32m---> 12\u001B[0m \u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_clients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_CLIENTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mServerConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mROUNDS\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\flwr\\simulation\\app.py:208\u001B[0m, in \u001B[0;36mstart_simulation\u001B[1;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001B[0m\n\u001B[0;32m    205\u001B[0m     ray\u001B[38;5;241m.\u001B[39mshutdown()\n\u001B[0;32m    207\u001B[0m \u001B[38;5;66;03m# Initialize Ray\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mray_init_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m cluster_resources \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mcluster_resources()\n\u001B[0;32m    210\u001B[0m log(\n\u001B[0;32m    211\u001B[0m     INFO,\n\u001B[0;32m    212\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFlower VCE: Ray initialized with resources: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    213\u001B[0m     cluster_resources,\n\u001B[0;32m    214\u001B[0m )\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py:103\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[0;32m    102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\worker.py:1567\u001B[0m, in \u001B[0;36minit\u001B[1;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001B[0m\n\u001B[0;32m   1534\u001B[0m     ray_params \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39m_private\u001B[38;5;241m.\u001B[39mparameter\u001B[38;5;241m.\u001B[39mRayParams(\n\u001B[0;32m   1535\u001B[0m         node_ip_address\u001B[38;5;241m=\u001B[39m_node_ip_address,\n\u001B[0;32m   1536\u001B[0m         object_ref_seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m         node_name\u001B[38;5;241m=\u001B[39m_node_name,\n\u001B[0;32m   1562\u001B[0m     )\n\u001B[0;32m   1563\u001B[0m     \u001B[38;5;66;03m# Start the Ray processes. We set shutdown_at_exit=False because we\u001B[39;00m\n\u001B[0;32m   1564\u001B[0m     \u001B[38;5;66;03m# shutdown the node in the ray.shutdown call that happens in the atexit\u001B[39;00m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;66;03m# handler. We still spawn a reaper process in case the atexit handler\u001B[39;00m\n\u001B[0;32m   1566\u001B[0m     \u001B[38;5;66;03m# isn't called.\u001B[39;00m\n\u001B[1;32m-> 1567\u001B[0m     _global_node \u001B[38;5;241m=\u001B[39m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_private\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNode\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1568\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1569\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshutdown_at_exit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1570\u001B[0m \u001B[43m        \u001B[49m\u001B[43mspawn_reaper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1571\u001B[0m \u001B[43m        \u001B[49m\u001B[43mray_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mray_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1572\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1573\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1574\u001B[0m     \u001B[38;5;66;03m# In this case, we are connecting to an existing cluster.\u001B[39;00m\n\u001B[0;32m   1575\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m num_cpus \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m num_gpus \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\node.py:310\u001B[0m, in \u001B[0;36mNode.__init__\u001B[1;34m(self, ray_params, head, shutdown_at_exit, spawn_reaper, connect_only, default_worker)\u001B[0m\n\u001B[0;32m    307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_head_processes()\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m connect_only:\n\u001B[1;32m--> 310\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_ray_processes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;66;03m# we should update the address info after the node has been started\u001B[39;00m\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\node.py:1357\u001B[0m, in \u001B[0;36mNode.start_ray_processes\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1353\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdestroy_external_storage()\n\u001B[0;32m   1355\u001B[0m \u001B[38;5;66;03m# Make sure we don't call `determine_plasma_store_config` multiple\u001B[39;00m\n\u001B[0;32m   1356\u001B[0m \u001B[38;5;66;03m# times to avoid printing multiple warnings.\u001B[39;00m\n\u001B[1;32m-> 1357\u001B[0m resource_spec \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_resource_spec\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1358\u001B[0m (\n\u001B[0;32m   1359\u001B[0m     plasma_directory,\n\u001B[0;32m   1360\u001B[0m     object_store_memory,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1364\u001B[0m     huge_pages\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ray_params\u001B[38;5;241m.\u001B[39mhuge_pages,\n\u001B[0;32m   1365\u001B[0m )\n\u001B[0;32m   1366\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_raylet(plasma_directory, object_store_memory)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\node.py:549\u001B[0m, in \u001B[0;36mNode.get_resource_spec\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    532\u001B[0m         logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoscaler overriding resources: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00menv_resources\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    533\u001B[0m     (\n\u001B[0;32m    534\u001B[0m         num_cpus,\n\u001B[0;32m    535\u001B[0m         num_gpus,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    538\u001B[0m         resources,\n\u001B[0;32m    539\u001B[0m     ) \u001B[38;5;241m=\u001B[39m merge_resources(env_resources, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ray_params\u001B[38;5;241m.\u001B[39mresources)\n\u001B[0;32m    540\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resource_spec \u001B[38;5;241m=\u001B[39m \u001B[43mResourceSpec\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    541\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ray_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_cpus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_cpus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_cpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    542\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ray_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_gpus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_gpus\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnum_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    543\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ray_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmemory\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ray_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobject_store_memory\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobject_store_memory\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\n\u001B[0;32m    546\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobject_store_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    547\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ray_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mredis_max_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m--> 549\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_head\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnode_ip_address\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_ip_address\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resource_spec\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\resource_spec.py:200\u001B[0m, in \u001B[0;36mResourceSpec.resolve\u001B[1;34m(self, is_head, node_ip_address)\u001B[0m\n\u001B[0;32m    191\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    192\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to start raylet with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_accelerators\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    193\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccelerator_resource_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut \u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccelerator_manager\u001B[38;5;241m.\u001B[39mget_visible_accelerator_ids_env_var()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    195\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontains \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvisible_accelerator_ids\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    196\u001B[0m     )\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_accelerators \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;66;03m# Try to automatically detect the number of accelerators.\u001B[39;00m\n\u001B[0;32m    199\u001B[0m     num_accelerators \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 200\u001B[0m         \u001B[43maccelerator_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_current_node_num_accelerators\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     )\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;66;03m# Don't use more accelerators than allowed by visible accelerator ids.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m visible_accelerator_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\MCS\\venv\\Lib\\site-packages\\ray\\_private\\accelerators\\nvidia_gpu.py:67\u001B[0m, in \u001B[0;36mNvidiaGPUAcceleratorManager.get_current_node_num_accelerators\u001B[1;34m()\u001B[0m\n\u001B[0;32m     65\u001B[0m     props \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAdapterCompatibility\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     66\u001B[0m     cmdargs \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWMIC\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPATH\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWin32_VideoController\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGET\u001B[39m\u001B[38;5;124m\"\u001B[39m, props]\n\u001B[1;32m---> 67\u001B[0m     lines \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmdargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msplitlines()[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m     68\u001B[0m     num_gpus \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m([x\u001B[38;5;241m.\u001B[39mrstrip() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m lines \u001B[38;5;28;01mif\u001B[39;00m x\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNVIDIA\u001B[39m\u001B[38;5;124m\"\u001B[39m)])\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m num_gpus\n",
      "File \u001B[1;32mD:\\Python\\Lib\\subprocess.py:466\u001B[0m, in \u001B[0;36mcheck_output\u001B[1;34m(timeout, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    463\u001B[0m         empty \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    464\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m empty\n\u001B[1;32m--> 466\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpopenargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[43m           \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstdout\n",
      "File \u001B[1;32mD:\\Python\\Lib\\subprocess.py:548\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[0m\n\u001B[0;32m    545\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m PIPE\n\u001B[0;32m    546\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstderr\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m PIPE\n\u001B[1;32m--> 548\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpopenargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m process:\n\u001B[0;32m    549\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    550\u001B[0m         stdout, stderr \u001B[38;5;241m=\u001B[39m process\u001B[38;5;241m.\u001B[39mcommunicate(\u001B[38;5;28minput\u001B[39m, timeout\u001B[38;5;241m=\u001B[39mtimeout)\n",
      "File \u001B[1;32mD:\\Python\\Lib\\subprocess.py:1026\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001B[0m\n\u001B[0;32m   1022\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_mode:\n\u001B[0;32m   1023\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[0;32m   1024\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m-> 1026\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1027\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1028\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1029\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1030\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1031\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1032\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1033\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1034\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocess_group\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdin, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstdout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr)):\n",
      "File \u001B[1;32mD:\\Python\\Lib\\subprocess.py:1538\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# Start the process\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1538\u001B[0m     hp, ht, pid, tid \u001B[38;5;241m=\u001B[39m _winapi\u001B[38;5;241m.\u001B[39mCreateProcess(executable, args,\n\u001B[0;32m   1539\u001B[0m                              \u001B[38;5;66;03m# no special security\u001B[39;00m\n\u001B[0;32m   1540\u001B[0m                              \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1541\u001B[0m                              \u001B[38;5;28mint\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m close_fds),\n\u001B[0;32m   1542\u001B[0m                              creationflags,\n\u001B[0;32m   1543\u001B[0m                              env,\n\u001B[0;32m   1544\u001B[0m                              cwd,\n\u001B[0;32m   1545\u001B[0m                              startupinfo)\n\u001B[0;32m   1546\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1547\u001B[0m     \u001B[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001B[39;00m\n\u001B[0;32m   1548\u001B[0m     \u001B[38;5;66;03m# handles that only the child should have open.  You need\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1551\u001B[0m     \u001B[38;5;66;03m# pipe will not close when the child process exits and the\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m     \u001B[38;5;66;03m# ReadFile will hang.\u001B[39;00m\n\u001B[0;32m   1553\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001B[0;32m   1554\u001B[0m                          c2pread, c2pwrite,\n\u001B[0;32m   1555\u001B[0m                          errread, errwrite)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] 系统找不到指定的文件。"
     ]
    }
   ],
   "source": [
    "params = get_parameters(Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES))\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,\n",
    "    fraction_evaluate=1.0,\n",
    "    min_fit_clients=NUM_CLIENTS,\n",
    "    min_evaluate_clients=NUM_CLIENTS,\n",
    "    min_available_clients=NUM_CLIENTS,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=ROUNDS),\n",
    "    strategy=strategy,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T19:59:29.667134Z",
     "start_time": "2023-11-07T19:59:27.390549200Z"
    }
   },
   "id": "801acac2af91f221"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Citation:   \n",
    "https://flower.dev/docs/framework/tutorial-series-get-started-with-flower-pytorch.html\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "626c29ee0b4c60f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-07T19:59:29.661459600Z"
    }
   },
   "id": "ca08814286feab15"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
