{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "472425b580dddcaf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.295453300Z",
     "start_time": "2023-10-19T20:51:16.282037800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "# import platform, cpuinfo, GPUtil, psutil\n",
    "# print(f\"OS: {platform.uname().system} {platform.uname().release}\")\n",
    "# print(f\"CPU: {cpuinfo.get_cpu_info()['brand_raw']}\")\n",
    "# print(f\"GPU: {GPUtil.getGPUs()[0].name}\")\n",
    "# print(f\"Memory: {psutil.virtual_memory().total / (1024 ** 3):.2f} GB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.295453300Z",
     "start_time": "2023-10-19T20:51:16.284465800Z"
    }
   },
   "id": "4ba5cc17f1cd99fd"
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "Version info: sys.version_info(major=3, minor=11, micro=4, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Python version:\", sys.version)\n",
    "print(\"Version info:\", sys.version_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.305590700Z",
     "start_time": "2023-10-19T20:51:16.292456600Z"
    }
   },
   "id": "a03c08d2241fc3fe"
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 2.0.1+cpu and Flower 1.5.0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.326006400Z",
     "start_time": "2023-10-19T20:51:16.299744200Z"
    }
   },
   "id": "f80cb111f6bc6cc6"
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d6ed94bf98631bf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.326006400Z",
     "start_time": "2023-10-19T20:51:16.310654800Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 3\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "IN_FEATURES = 3\n",
    "HIDDEN_LAYERS = 128\n",
    "OUT_FEATURES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    df = pd.read_csv('./datasets/label_data.csv')\n",
    "    df = df.rename(columns={'label': 'target'})\n",
    "    \n",
    "    feature = df.iloc[:, :-1]\n",
    "    target = df.loc[:, 'target']\n",
    "    feature = torch.Tensor(feature.to_numpy())\n",
    "    target = torch.tensor(target.to_numpy())\n",
    "    tensor_data = TensorDataset(feature, target)\n",
    "    \n",
    "    number_rows = len(feature)\n",
    "    test_split = int(number_rows * 0.2)\n",
    "    train_split = number_rows - test_split\n",
    "    train_set, test_set = random_split(tensor_data, [train_split, test_split])  \n",
    "\n",
    "    # split_ratio = 0.8\n",
    "    # split_index = int(len(df) * split_ratio)\n",
    "    # \n",
    "    # train_set = tensor_data.iloc[:split_index, :]\n",
    "    # test_set = tensor_data.iloc[split_index:, :]\n",
    "    \n",
    "    part_size = len(train_set) // NUM_CLIENTS\n",
    "    length = [part_size] * NUM_CLIENTS  # lengths for each client\n",
    "    \n",
    "    # Split the test set evenly into thirds, removing the remainders\n",
    "    # random_choose = np.random.choice(train_set.index, (len(train_set) % NUM_CLIENTS), replace=False)\n",
    "    # train_set = train_set.drop(random_choose)\n",
    "    \n",
    "    datasets = random_split(train_set, length, generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_loader = []\n",
    "    val_loader = []\n",
    "    \n",
    "    for data in datasets:\n",
    "        val_length = len(data) // 10\n",
    "        train_length = len(data) - val_length\n",
    "        length = [train_length, val_length]\n",
    "        train_data, val_data = random_split(data, length, generator=torch.Generator().manual_seed(42))\n",
    "        \n",
    "        train_loader.append(DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        val_loader.append(DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True))\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return train_loader, val_loader, test_loader\n",
    "    \n",
    "train_loader, val_loader, test_loader = load_datasets()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.550710400Z",
     "start_time": "2023-10-19T20:51:16.317028100Z"
    }
   },
   "id": "7953758d82a33194"
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(IN_FEATURES, HIDDEN_LAYERS), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYERS, HIDDEN_LAYERS), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_LAYERS, OUT_FEATURES), \n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.559203600Z",
     "start_time": "2023-10-19T20:51:16.553693900Z"
    }
   },
   "id": "7de944941f3254ed"
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1): \n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        \n",
    "        for feature, target in train_loader:\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(feature)\n",
    "            train_loss = criterion(output, target)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += train_loss\n",
    "            total += target.size(0)\n",
    "            correct += (torch.max(output.data, 1)[1] == target).sum().item()\n",
    "            \n",
    "        epoch_loss /= len(train_loader.dataset)\n",
    "        epoch_accuracy = correct / total\n",
    "        \n",
    "        print(f\"Epoch {epoch}: train loss: {epoch_loss:.8f}, accuracy: {epoch_accuracy:.8f}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.567960100Z",
     "start_time": "2023-10-19T20:51:16.557203200Z"
    }
   },
   "id": "3b7767fe074ec24"
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    model.eval()\n",
    " \n",
    "    with torch.no_grad():\n",
    "        for feature, target in test_loader:\n",
    "            feature, target = feature.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(feature)\n",
    "            loss += criterion(output, target).item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "        loss /= len(test_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        return loss, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:16.575453200Z",
     "start_time": "2023-10-19T20:51:16.567960100Z"
    }
   },
   "id": "b55c029f8b011706"
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss: 0.00454832, accuracy: 0.85926477.\n",
      "Epoch 2: train loss: 0.00453187, accuracy: 0.86018749.\n",
      "Epoch 3: train loss: 0.00453205, accuracy: 0.86018749.\n",
      "Epoch 4: train loss: 0.00453197, accuracy: 0.86018749.\n",
      "Epoch 5: train loss: 0.00453197, accuracy: 0.86018749.\n",
      "Epoch 6: train loss: 0.00453214, accuracy: 0.86018749.\n",
      "Epoch 7: train loss: 0.00453184, accuracy: 0.86018749.\n",
      "Epoch 8: train loss: 0.00453201, accuracy: 0.86018749.\n",
      "Epoch 9: train loss: 0.00453183, accuracy: 0.86018749.\n",
      "Epoch 10: train loss: 0.00453188, accuracy: 0.86018749.\n",
      "Final test set performance: loss: 0.00451649, accuracy: 0.86325624\n"
     ]
    }
   ],
   "source": [
    "train_loader = train_loader[1]\n",
    "val_loader = val_loader[1]\n",
    "model = Network(IN_FEATURES, HIDDEN_LAYERS, OUT_FEATURES).to(DEVICE)\n",
    "\n",
    "train(model, train_loader, EPOCHS)\n",
    "\n",
    "loss, accuracy = test(model, val_loader)\n",
    "print(f\"Final test set performance: \\n\\tloss: {loss:.8f}, accuracy: {accuracy:.8f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:45.223183500Z",
     "start_time": "2023-10-19T20:51:16.576489600Z"
    }
   },
   "id": "8bacc3940f61904b"
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-19T20:51:45.224191300Z",
     "start_time": "2023-10-19T20:51:45.218581900Z"
    }
   },
   "id": "53bb07e9fc48198c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
